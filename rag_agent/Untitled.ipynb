{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab4a331-b545-481e-8b1d-fba629016b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52e703f-a53e-45c1-85fc-fabd6d3f3113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"QDRANT_URL\"] = \"https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333\"\n",
    "os.environ[\"QDRANT_API_KEY\"] = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.zfOj_fNcPVKfsRLngk5n4gU5K4t-XLefyKTHfUjZ6qA\"  \n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "qdrant_url = os.environ[\"QDRANT_URL\"]\n",
    "qdrant_api_key = os.environ.get(\"QDRANT_API_KEY\")\n",
    "\n",
    "print(\"Environment variables set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a57184-d5c9-4b27-91c2-94d11560a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:vector_search.qdrant_vector_store:Qdrant client initialized and connection verified.\n",
      "INFO:httpx:HTTP Request: PUT https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:vector_search.qdrant_vector_store:Collection 'test_collection' created.\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:vector_search.qdrant_vector_store:Hybrid QdrantVectorStore initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant vector store created for collection: test_collection\n"
     ]
    }
   ],
   "source": [
    "# Создание коллекции в Qdrant Cloud\n",
    "collection_name = \"test_collection\"\n",
    "vector_store = setup_qdrant_vector_store(\n",
    "    collection_name=collection_name,\n",
    "    openai_api_key=openai_api_key,\n",
    "    qdrant_url=qdrant_url,\n",
    "    qdrant_api_key=qdrant_api_key\n",
    ")\n",
    "print(f\"Qdrant vector store created for collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f596f40-085f-49b2-a76a-b009811c1b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.3 (main, Apr  9 2025, 08:55:02) [GCC 11.4.0]\n",
      "Python executable: /home/oleg/PycharmProjects/adkllama/rag_agent/venv/bin/python3.13\n",
      "pandas version: 2.2.3\n",
      "pytz version: 2025.2\n",
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from llama_index.core import VectorStoreIndex, Document, SimpleDirectoryReader\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from vector_search.qdrant_vector_store import setup_qdrant_vector_store\n",
    "from vector_search.hybrid_retriever import HybridRetriever\n",
    "from vector_search.reranker import Reranker\n",
    "from vector_search.document_loader import DocumentLoader\n",
    "from vector_search.custom_query_engine_tool import CustomQueryEngineTool\n",
    "from vector_search.utils import evaluate_retrieval\n",
    "import pandas as pd\n",
    "\n",
    "# Диагностика окружения\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "import pytz\n",
    "print(f\"pytz version: {pytz.__version__}\")\n",
    "import llama_index\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdbee69-6923-437c-b254-c3fad7441f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Index created with 2 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents into Qdrant\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Document\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Создание тестовых документов\n",
    "documents_dir = \"test_documents\"\n",
    "os.makedirs(documents_dir, exist_ok=True)\n",
    "with open(os.path.join(documents_dir, \"doc1.txt\"), \"w\") as f:\n",
    "    f.write(\"Investment opportunities in MENA region: Tech startups are booming.\")\n",
    "with open(os.path.join(documents_dir, \"doc2.txt\"), \"w\") as f:\n",
    "    f.write(\"Real estate investment trends in the MENA region.\")\n",
    "\n",
    "# Загрузка документов\n",
    "reader = SimpleDirectoryReader(input_dir=documents_dir)\n",
    "documents = reader.load_data()\n",
    "\n",
    "# Создание индекса в Qdrant\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store  # Передаем vector_store напрямую\n",
    ")\n",
    "logger.info(f\"Index created with {len(documents)} documents\")\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74236c20-f049-4e47-a0d6-9420f6273fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:bm25s:Building index from IDs objects\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cuda:0\n",
      "INFO:vector_search.reranker:Reranker initialized with model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever configured\n"
     ]
    }
   ],
   "source": [
    "# Блок 5: Настройка гибридного поиска\n",
    "vector_retriever = VectorIndexRetriever(index=index, similarity_top_k=10)\n",
    "bm25_retriever = BM25Retriever.from_defaults(index=index, similarity_top_k=10)\n",
    "reranker = Reranker()\n",
    "hybrid_retriever = HybridRetriever(\n",
    "    vector_retriever=vector_retriever,\n",
    "    bm25_retriever=bm25_retriever,\n",
    "    reranker=reranker\n",
    ")\n",
    "print(\"Hybrid retriever configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc396757-e77c-46b1-81a3-812e63276036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query engine tool created\n"
     ]
    }
   ],
   "source": [
    "# Блок 6: Создание инструмента для запросов\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from vector_search.custom_query_engine_tool import CustomQueryEngineTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=hybrid_retriever,\n",
    "    response_synthesizer=llm\n",
    ")\n",
    "tool = CustomQueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"test_tool\",\n",
    "    description=\"Test RAG engine\"\n",
    ")\n",
    "print(\"Query engine tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a925b7a-85bd-439f-b9ee-cefc1153b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 7: Тестовый запрос\n",
    "\n",
    "tool = CustomQueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"test_tool\",\n",
    "    description=\"Test RAG engine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d0006a-04da-469a-8b03-db4e77b1aa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:vector_search.custom_query_engine_tool:Error processing query: Как LLAMA 2 использует reinforcement learning?, Error: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🧠 Ответ:\n",
       "Error processing query: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "query = \"Как LLAMA 2 использует reinforcement learning?\"\n",
    "response = tool.call(query)\n",
    "\n",
    "Markdown(f\"### 🧠 Ответ:\\n{response.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05bea007-4110-44c5-a7e5-ec1f9ac1e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим кэшированную директорию (если используется)\n",
    "reader = SimpleDirectoryReader(input_dir=documents_dir, recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10bced15-bb75-44df-9350-752b2969bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 documents into Qdrant\n"
     ]
    }
   ],
   "source": [
    "more_docs = [\n",
    "    \"LLAMA 2 использует reinforcement learning from human feedback (RLHF) для дообучения моделей.\",\n",
    "    \"Сравнение LLAMA и GPT показывает различия в архитектуре и тренировочном корпусе.\",\n",
    "    \"Нейросети применяются для генерации текста, перевода, классификации и ответа на вопросы.\",\n",
    "    \"LLAMA 2 открыта для исследовательского использования и поддерживает модели до 70B параметров.\",\n",
    "    \"RLHF включает в себя этап предпочтения — модель учится из выборов человека.\",\n",
    "    \"Meta выпустила LLAMA 2 в 2023 году, улучшив производительность и стабильность генерации.\",\n",
    "    \"Документация LLAMA 2 объясняет, как применять модель в продакшене.\",\n",
    "    \"Тренировка LLAMA 2 включает supervision и fine-tuning на выбранных задачах.\",\n",
    "    \"LLAMA используется для чат-ботов, ассистентов и интеграции в приложения.\",\n",
    "    \"Reinforcement learning помогает моделям формировать более «человеческие» ответы.\"\n",
    "]\n",
    "\n",
    "# Запишем в отдельные файлы\n",
    "for i, text in enumerate(more_docs, start=3):\n",
    "    with open(os.path.join(documents_dir, f\"doc{i}.txt\"), \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "documents = reader.load_data()\n",
    "\n",
    "# Создание нового индекса\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b5ccde-0801-482d-817d-67ba20fe720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:vector_search.custom_query_engine_tool:Error processing query: Как LLAMA 2 использует reinforcement learning?, Error: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### 🧠 Ответ:\n",
       "Error processing query: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "query = \"Как LLAMA 2 использует reinforcement learning?\"\n",
    "response = tool.call(query)\n",
    "\n",
    "Markdown(f\"### 🧠 Ответ:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1658e53b-5313-4008-b24e-78e826644847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CollectionInfo' object has no attribute 'collection_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m client = QdrantClient(\n\u001b[32m      8\u001b[39m     url=os.environ[\u001b[33m\"\u001b[39m\u001b[33mQDRANT_URL\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m     api_key=os.environ[\u001b[33m\"\u001b[39m\u001b[33mQDRANT_API_KEY\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m collection_info = client.get_collection(collection_name=\u001b[33m\"\u001b[39m\u001b[33mtest_collection\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcollection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPoints count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_info.points_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collection_info.points_count > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/adkllama/rag_agent/venv/lib/python3.13/site-packages/pydantic/main.py:994\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'CollectionInfo' object has no attribute 'collection_name'"
     ]
    }
   ],
   "source": [
    "# Временный блок: Проверка содержимого коллекции\n",
    "from qdrant_client import QdrantClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = QdrantClient(\n",
    "    url=os.environ[\"QDRANT_URL\"],\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"]\n",
    ")\n",
    "collection_info = client.get_collection(collection_name=\"test_collection\")\n",
    "print(f\"Collection: {collection_info.collection_name}\")\n",
    "print(f\"Points count: {collection_info.points_count}\")\n",
    "\n",
    "if collection_info.points_count > 0:\n",
    "    points = client.scroll(\n",
    "        collection_name=\"test_collection\",\n",
    "        limit=10\n",
    "    )[0]\n",
    "    for point in points:\n",
    "        print(f\"Point ID: {point.id}, Payload: {point.payload}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9d9abf-244a-4d3a-91b7-a34c5b1a41b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qdrant_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqdrant_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhttp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountRequest\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m collection_info = \u001b[43mqdrant_client\u001b[49m.get_collection(collection_name)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m points_count = qdrant_client.count(collection_name=collection_name, count_request=CountRequest(exact=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[31mNameError\u001b[39m: name 'qdrant_client' is not defined"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http.models import CountRequest\n",
    "\n",
    "collection_info = qdrant_client.get_collection(collection_name)\n",
    "print(f\"Collection info: {collection_info}\")\n",
    "\n",
    "points_count = qdrant_client.count(collection_name=collection_name, count_request=CountRequest(exact=True))\n",
    "print(f\"Points in collection: {points_count.count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93b65480-bcf7-4bdc-a5d6-362496adbacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DocumentLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m         f.write(text)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Создание загрузчика документов и загрузка документов\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m loader = \u001b[43mDocumentLoader\u001b[49m(directory_path=documents_dir)\n\u001b[32m     21\u001b[39m documents = loader.load_documents()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Создание нового индекса\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'DocumentLoader' is not defined"
     ]
    }
   ],
   "source": [
    "more_docs = [\n",
    "    \"LLAMA 2 использует reinforcement learning from human feedback (RLHF) для дообучения моделей.\",\n",
    "    \"Сравнение LLAMA и GPT показывает различия в архитектуре и тренировочном корпусе.\",\n",
    "    \"Нейросети применяются для генерации текста, перевода, классификации и ответа на вопросы.\",\n",
    "    \"LLAMA 2 открыта для исследовательского использования и поддерживает модели до 70B параметров.\",\n",
    "    \"RLHF включает в себя этап предпочтения — модель учится из выборов человека.\",\n",
    "    \"Meta выпустила LLAMA 2 в 2023 году, улучшив производительность и стабильность генерации.\",\n",
    "    \"Документация LLAMA 2 объясняет, как применять модель в продакшене.\",\n",
    "    \"Тренировка LLAMA 2 включает supervision и fine-tuning на выбранных задачах.\",\n",
    "    \"LLAMA используется для чат-ботов, ассистентов и интеграции в приложения.\",\n",
    "    \"Reinforcement learning помогает моделям формировать более «человеческие» ответы.\"\n",
    "]\n",
    "\n",
    "# Запишем в отдельные файлы\n",
    "for i, text in enumerate(more_docs, start=3):\n",
    "    with open(os.path.join(documents_dir, f\"doc{i}.txt\"), \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Создание загрузчика документов и загрузка документов\n",
    "loader = DocumentLoader(directory_path=documents_dir)\n",
    "documents = loader.load_documents()\n",
    "\n",
    "# Создание нового индекса\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "191b798c-a32f-4a75-94e3-8c485676a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vector_search.document_loader:Loaded 12 documents from test_documents\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 documents into Qdrant\n"
     ]
    }
   ],
   "source": [
    "more_docs = [\n",
    "    \"LLAMA 2 использует reinforcement learning from human feedback (RLHF) для дообучения моделей.\",\n",
    "    \"Сравнение LLAMA и GPT показывает различия в архитектуре и тренировочном корпусе.\",\n",
    "    \"Нейросети применяются для генерации текста, перевода, классификации и ответа на вопросы.\",\n",
    "    \"LLAMA 2 открыта для исследовательского использования и поддерживает модели до 70B параметров.\",\n",
    "    \"RLHF включает в себя этап предпочтения — модель учится из выборов человека.\",\n",
    "    \"Meta выпустила LLAMA 2 в 2023 году, улучшив производительность и стабильность генерации.\",\n",
    "    \"Документация LLAMA 2 объясняет, как применять модель в продакшене.\",\n",
    "    \"Тренировка LLAMA 2 включает supervision и fine-tuning на выбранных задачах.\",\n",
    "    \"LLAMA используется для чат-ботов, ассистентов и интеграции в приложения.\",\n",
    "    \"Reinforcement learning помогает моделям формировать более «человеческие» ответы.\"\n",
    "]\n",
    "\n",
    "# Запишем в отдельные файлы\n",
    "for i, text in enumerate(more_docs, start=3):\n",
    "    with open(os.path.join(documents_dir, f\"doc{i}.txt\"), \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Создание загрузчика документов и загрузка документов\n",
    "loader = DocumentLoader(directory_path=documents_dir)\n",
    "documents = loader.load_documents()\n",
    "\n",
    "# Создание нового индекса\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b776c1-9a99-4162-8dda-9c7101ae7ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
