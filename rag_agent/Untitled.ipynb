{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab4a331-b545-481e-8b1d-fba629016b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a52e703f-a53e-45c1-85fc-fabd6d3f3113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables set\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"QDRANT_URL\"] = \"https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333\"\n",
    "os.environ[\"QDRANT_API_KEY\"] = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.zfOj_fNcPVKfsRLngk5n4gU5K4t-XLefyKTHfUjZ6qA\"  \n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "qdrant_url = os.environ[\"QDRANT_URL\"]\n",
    "qdrant_api_key = os.environ.get(\"QDRANT_API_KEY\")\n",
    "\n",
    "print(\"Environment variables set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42a57184-d5c9-4b27-91c2-94d11560a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:vector_search.qdrant_vector_store:Qdrant client initialized and connection verified.\n",
      "INFO:httpx:HTTP Request: PUT https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:vector_search.qdrant_vector_store:Collection 'test_collection' created.\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection/exists \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n",
      "INFO:vector_search.qdrant_vector_store:Hybrid QdrantVectorStore initialized successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant vector store created for collection: test_collection\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant Cloud\n",
    "collection_name = \"test_collection\"\n",
    "vector_store = setup_qdrant_vector_store(\n",
    "    collection_name=collection_name,\n",
    "    openai_api_key=openai_api_key,\n",
    "    qdrant_url=qdrant_url,\n",
    "    qdrant_api_key=qdrant_api_key\n",
    ")\n",
    "print(f\"Qdrant vector store created for collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f596f40-085f-49b2-a76a-b009811c1b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.13.3 (main, Apr  9 2025, 08:55:02) [GCC 11.4.0]\n",
      "Python executable: /home/oleg/PycharmProjects/adkllama/rag_agent/venv/bin/python3.13\n",
      "pandas version: 2.2.3\n",
      "pytz version: 2025.2\n",
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from llama_index.core import VectorStoreIndex, Document, SimpleDirectoryReader\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from vector_search.qdrant_vector_store import setup_qdrant_vector_store\n",
    "from vector_search.hybrid_retriever import HybridRetriever\n",
    "from vector_search.reranker import Reranker\n",
    "from vector_search.document_loader import DocumentLoader\n",
    "from vector_search.custom_query_engine_tool import CustomQueryEngineTool\n",
    "from vector_search.utils import evaluate_retrieval\n",
    "import pandas as pd\n",
    "\n",
    "# –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "import pytz\n",
    "print(f\"pytz version: {pytz.__version__}\")\n",
    "import llama_index\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdbee69-6923-437c-b254-c3fad7441f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Index created with 2 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents into Qdrant\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, Document\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "documents_dir = \"test_documents\"\n",
    "os.makedirs(documents_dir, exist_ok=True)\n",
    "with open(os.path.join(documents_dir, \"doc1.txt\"), \"w\") as f:\n",
    "    f.write(\"Investment opportunities in MENA region: Tech startups are booming.\")\n",
    "with open(os.path.join(documents_dir, \"doc2.txt\"), \"w\") as f:\n",
    "    f.write(\"Real estate investment trends in the MENA region.\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "reader = SimpleDirectoryReader(input_dir=documents_dir)\n",
    "documents = reader.load_data()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ Qdrant\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store  # –ü–µ—Ä–µ–¥–∞–µ–º vector_store –Ω–∞–ø—Ä—è–º—É—é\n",
    ")\n",
    "logger.info(f\"Index created with {len(documents)} documents\")\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74236c20-f049-4e47-a0d6-9420f6273fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:bm25s:Building index from IDs objects\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cuda:0\n",
      "INFO:vector_search.reranker:Reranker initialized with model: cross-encoder/ms-marco-MiniLM-L-6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever configured\n"
     ]
    }
   ],
   "source": [
    "# –ë–ª–æ–∫ 5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞\n",
    "vector_retriever = VectorIndexRetriever(index=index, similarity_top_k=10)\n",
    "bm25_retriever = BM25Retriever.from_defaults(index=index, similarity_top_k=10)\n",
    "reranker = Reranker()\n",
    "hybrid_retriever = HybridRetriever(\n",
    "    vector_retriever=vector_retriever,\n",
    "    bm25_retriever=bm25_retriever,\n",
    "    reranker=reranker\n",
    ")\n",
    "print(\"Hybrid retriever configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc396757-e77c-46b1-81a3-812e63276036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query engine tool created\n"
     ]
    }
   ],
   "source": [
    "# –ë–ª–æ–∫ 6: –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from vector_search.custom_query_engine_tool import CustomQueryEngineTool\n",
    "from llama_index.llms.openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=hybrid_retriever,\n",
    "    response_synthesizer=llm\n",
    ")\n",
    "tool = CustomQueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"test_tool\",\n",
    "    description=\"Test RAG engine\"\n",
    ")\n",
    "print(\"Query engine tool created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a925b7a-85bd-439f-b9ee-cefc1153b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë–ª–æ–∫ 7: –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å\n",
    "\n",
    "tool = CustomQueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"test_tool\",\n",
    "    description=\"Test RAG engine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7d0006a-04da-469a-8b03-db4e77b1aa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:vector_search.custom_query_engine_tool:Error processing query: –ö–∞–∫ LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning?, Error: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† –û—Ç–≤–µ—Ç:\n",
       "Error processing query: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "query = \"–ö–∞–∫ LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning?\"\n",
    "response = tool.call(query)\n",
    "\n",
    "Markdown(f\"### üß† –û—Ç–≤–µ—Ç:\\n{response.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05bea007-4110-44c5-a7e5-ec1f9ac1e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£–¥–∞–ª–∏–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)\n",
    "reader = SimpleDirectoryReader(input_dir=documents_dir, recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10bced15-bb75-44df-9350-752b2969bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 documents into Qdrant\n"
     ]
    }
   ],
   "source": [
    "more_docs = [\n",
    "    \"LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning from human feedback (RLHF) –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.\",\n",
    "    \"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ LLAMA –∏ GPT –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ.\",\n",
    "    \"–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –ø–µ—Ä–µ–≤–æ–¥–∞, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.\",\n",
    "    \"LLAMA 2 –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –¥–æ 70B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\",\n",
    "    \"RLHF –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —ç—Ç–∞–ø –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –∏–∑ –≤—ã–±–æ—Ä–æ–≤ —á–µ–ª–æ–≤–µ–∫–∞.\",\n",
    "    \"Meta –≤—ã–ø—É—Å—Ç–∏–ª–∞ LLAMA 2 –≤ 2023 –≥–æ–¥—É, —É–ª—É—á—à–∏–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\",\n",
    "    \"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è LLAMA 2 –æ–±—ä—è—Å–Ω—è–µ—Ç, –∫–∞–∫ –ø—Ä–∏–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ.\",\n",
    "    \"–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ LLAMA 2 –≤–∫–ª—é—á–∞–µ—Ç supervision –∏ fine-tuning –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.\",\n",
    "    \"LLAMA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —á–∞—Ç-–±–æ—Ç–æ–≤, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.\",\n",
    "    \"Reinforcement learning –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª—è–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–µ ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ¬ª –æ—Ç–≤–µ—Ç—ã.\"\n",
    "]\n",
    "\n",
    "# –ó–∞–ø–∏—à–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "for i, text in enumerate(more_docs, start=3):\n",
    "    with open(os.path.join(documents_dir, f\"doc{i}.txt\"), \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "documents = reader.load_data()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46b5ccde-0801-482d-817d-67ba20fe720b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "ERROR:vector_search.custom_query_engine_tool:Error processing query: –ö–∞–∫ LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning?, Error: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### üß† –û—Ç–≤–µ—Ç:\n",
       "Error processing query: k of 10 is larger than the number of available scores, which is 2 (corpus size should be larger than top-k). Please set with a smaller k or increase the size of corpus."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "query = \"–ö–∞–∫ LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning?\"\n",
    "response = tool.call(query)\n",
    "\n",
    "Markdown(f\"### üß† –û—Ç–≤–µ—Ç:\\n{response.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1658e53b-5313-4008-b24e-78e826644847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://82408bbb-de19-463e-ac0c-3cfb66e9e7b1.us-east-1-0.aws.cloud.qdrant.io:6333/collections/test_collection \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CollectionInfo' object has no attribute 'collection_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m client = QdrantClient(\n\u001b[32m      8\u001b[39m     url=os.environ[\u001b[33m\"\u001b[39m\u001b[33mQDRANT_URL\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m      9\u001b[39m     api_key=os.environ[\u001b[33m\"\u001b[39m\u001b[33mQDRANT_API_KEY\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m )\n\u001b[32m     11\u001b[39m collection_info = client.get_collection(collection_name=\u001b[33m\"\u001b[39m\u001b[33mtest_collection\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcollection_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPoints count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_info.points_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collection_info.points_count > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PycharmProjects/adkllama/rag_agent/venv/lib/python3.13/site-packages/pydantic/main.py:994\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'CollectionInfo' object has no attribute 'collection_name'"
     ]
    }
   ],
   "source": [
    "# –í—Ä–µ–º–µ–Ω–Ω—ã–π –±–ª–æ–∫: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏\n",
    "from qdrant_client import QdrantClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = QdrantClient(\n",
    "    url=os.environ[\"QDRANT_URL\"],\n",
    "    api_key=os.environ[\"QDRANT_API_KEY\"]\n",
    ")\n",
    "collection_info = client.get_collection(collection_name=\"test_collection\")\n",
    "print(f\"Collection: {collection_info.collection_name}\")\n",
    "print(f\"Points count: {collection_info.points_count}\")\n",
    "\n",
    "if collection_info.points_count > 0:\n",
    "    points = client.scroll(\n",
    "        collection_name=\"test_collection\",\n",
    "        limit=10\n",
    "    )[0]\n",
    "    for point in points:\n",
    "        print(f\"Point ID: {point.id}, Payload: {point.payload}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9d9abf-244a-4d3a-91b7-a34c5b1a41b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qdrant_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqdrant_client\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhttp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CountRequest\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m collection_info = \u001b[43mqdrant_client\u001b[49m.get_collection(collection_name)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollection info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m points_count = qdrant_client.count(collection_name=collection_name, count_request=CountRequest(exact=\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "\u001b[31mNameError\u001b[39m: name 'qdrant_client' is not defined"
     ]
    }
   ],
   "source": [
    "from qdrant_client.http.models import CountRequest\n",
    "\n",
    "collection_info = qdrant_client.get_collection(collection_name)\n",
    "print(f\"Collection info: {collection_info}\")\n",
    "\n",
    "points_count = qdrant_client.count(collection_name=collection_name, count_request=CountRequest(exact=True))\n",
    "print(f\"Points in collection: {points_count.count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93b65480-bcf7-4bdc-a5d6-362496adbacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DocumentLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m         f.write(text)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m loader = \u001b[43mDocumentLoader\u001b[49m(directory_path=documents_dir)\n\u001b[32m     21\u001b[39m documents = loader.load_documents()\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'DocumentLoader' is not defined"
     ]
    }
   ],
   "source": [
    "more_docs = [\n",
    "    \"LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning from human feedback (RLHF) –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.\",\n",
    "    \"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ LLAMA –∏ GPT –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ.\",\n",
    "    \"–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –ø–µ—Ä–µ–≤–æ–¥–∞, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.\",\n",
    "    \"LLAMA 2 –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –¥–æ 70B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\",\n",
    "    \"RLHF –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —ç—Ç–∞–ø –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –∏–∑ –≤—ã–±–æ—Ä–æ–≤ —á–µ–ª–æ–≤–µ–∫–∞.\",\n",
    "    \"Meta –≤—ã–ø—É—Å—Ç–∏–ª–∞ LLAMA 2 –≤ 2023 –≥–æ–¥—É, —É–ª—É—á—à–∏–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\",\n",
    "    \"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è LLAMA 2 –æ–±—ä—è—Å–Ω—è–µ—Ç, –∫–∞–∫ –ø—Ä–∏–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ.\",\n",
    "    \"–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ LLAMA 2 –≤–∫–ª—é—á–∞–µ—Ç supervision –∏ fine-tuning –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.\",\n",
    "    \"LLAMA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —á–∞—Ç-–±–æ—Ç–æ–≤, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.\",\n",
    "    \"Reinforcement learning –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª—è–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–µ ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ¬ª –æ—Ç–≤–µ—Ç—ã.\"\n",
    "]\n",
    "\n",
    "# –ó–∞–ø–∏—à–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "for i, text in enumerate(more_docs, start=3):\n",
    "    with open(os.path.join(documents_dir, f\"doc{i}.txt\"), \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "loader = DocumentLoader(directory_path=documents_dir)\n",
    "documents = loader.load_documents()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "191b798c-a32f-4a75-94e3-8c485676a7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vector_search.document_loader:Loaded 12 documents from test_documents\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 documents into Qdrant\n"
     ]
    }
   ],
   "source": [
    "more_docs = [\n",
    "    \"LLAMA 2 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç reinforcement learning from human feedback (RLHF) –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.\",\n",
    "    \"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ LLAMA –∏ GPT –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–∏—è –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ.\",\n",
    "    \"–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞, –ø–µ—Ä–µ–≤–æ–¥–∞, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.\",\n",
    "    \"LLAMA 2 –æ—Ç–∫—Ä—ã—Ç–∞ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏ –¥–æ 70B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\",\n",
    "    \"RLHF –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è —ç—Ç–∞–ø –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è ‚Äî –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –∏–∑ –≤—ã–±–æ—Ä–æ–≤ —á–µ–ª–æ–≤–µ–∫–∞.\",\n",
    "    \"Meta –≤—ã–ø—É—Å—Ç–∏–ª–∞ LLAMA 2 –≤ 2023 –≥–æ–¥—É, —É–ª—É—á—à–∏–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\",\n",
    "    \"–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è LLAMA 2 –æ–±—ä—è—Å–Ω—è–µ—Ç, –∫–∞–∫ –ø—Ä–∏–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ.\",\n",
    "    \"–¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ LLAMA 2 –≤–∫–ª—é—á–∞–µ—Ç supervision –∏ fine-tuning –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö.\",\n",
    "    \"LLAMA –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —á–∞—Ç-–±–æ—Ç–æ–≤, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–≤ –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.\",\n",
    "    \"Reinforcement learning –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª—è–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –±–æ–ª–µ–µ ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–µ¬ª –æ—Ç–≤–µ—Ç—ã.\"\n",
    "]\n",
    "\n",
    "# –ó–∞–ø–∏—à–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã\n",
    "for i, text in enumerate(more_docs, start=3):\n",
    "    with open(os.path.join(documents_dir, f\"doc{i}.txt\"), \"w\") as f:\n",
    "        f.write(text)\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "loader = DocumentLoader(directory_path=documents_dir)\n",
    "documents = loader.load_documents()\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    vector_store=vector_store\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents into Qdrant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b776c1-9a99-4162-8dda-9c7101ae7ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
